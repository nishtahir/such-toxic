# Such Toxic

> Due to the nature of the work, this repository contains offensive content including hate speech. This does not reflect
> the views of the author.

A proof of concept ML model to detect and flag toxic comments for content moderation.
The model is trained on the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) dataset from Kaggle.

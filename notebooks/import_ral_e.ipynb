{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from prisma import Prisma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/5261022518c9417692ab0d3315ffb9e0/such-toxic\"\n",
    "sentence_transformer_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "ral_e_dataset = \"../datasets/retrain_reddit_abuse_test.txt\"\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'comment_text': 'Hello',\n",
       "  'toxic': 0.01214311458170414,\n",
       "  'severe_toxic': 0.0004117148055229336,\n",
       "  'obscene': 0.00260039116255939,\n",
       "  'threat': 0.00035658563137985766,\n",
       "  'insult': 0.003171957330778241,\n",
       "  'identity_hate': 0.0006483225733973086},\n",
       " {'comment_text': 'World',\n",
       "  'toxic': 0.06567952781915665,\n",
       "  'severe_toxic': 0.0016220887191593647,\n",
       "  'obscene': 0.027771923691034317,\n",
       "  'threat': 0.001004645018838346,\n",
       "  'insult': 0.008807024918496609,\n",
       "  'identity_hate': 0.0010928488336503506}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_transformer = SentenceTransformer(sentence_transformer_model, device=device)\n",
    "such_toxic = mlflow.pytorch.load_model(model_uri).to(device)\n",
    "\n",
    "\n",
    "def classifiy_batch(batch):\n",
    "    embeddings = sentence_transformer.encode(batch, convert_to_tensor=True)\n",
    "    out = such_toxic(embeddings).cpu().detach().numpy().tolist()\n",
    "    out = zip(batch, out)\n",
    "    out = map(\n",
    "        lambda x: {\n",
    "            \"comment_text\": x[0],\n",
    "            \"toxic\": x[1][0],\n",
    "            \"severe_toxic\": x[1][1],\n",
    "            \"obscene\": x[1][2],\n",
    "            \"threat\": x[1][3],\n",
    "            \"insult\": x[1][4],\n",
    "            \"identity_hate\": x[1][5],\n",
    "        },\n",
    "        out,\n",
    "    )\n",
    "    return list(out)\n",
    "\n",
    "\n",
    "classifiy_batch([\"Hello\", \"World\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "db = Prisma()\n",
    "db.connect()\n",
    "\n",
    "\n",
    "def process_batch(batch):\n",
    "    out = classifiy_batch(batch)\n",
    "    for item in out:\n",
    "        db.comments.create(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14935it [04:41, 53.01it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(ral_e_dataset, \"r\") as file:\n",
    "    batch = []\n",
    "    for line in tqdm(file):\n",
    "        batch.append(line)\n",
    "        if len(batch) == 100:\n",
    "            process_batch(batch)\n",
    "            batch = []\n",
    "    if batch:\n",
    "        process_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

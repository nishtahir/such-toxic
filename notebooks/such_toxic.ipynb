{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjaFBQSXLbfZ",
    "outputId": "70715375-e7fd-468e-d93b-1835bfe431fe"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from such_toxic.text_classifier import TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP3KWVFb-ZgB",
    "outputId": "d2d9f071-7a16-4719-8d84-9b72f4c46e4d"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dataset_path = \"../target/wiki_data_all_human.json\"\n",
    "\n",
    "sentence_transformer_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "experiment_name = \"such-toxic\"\n",
    "model_name = \"such_toxic\"\n",
    "\n",
    "max_length = 512\n",
    "num_classes = 6\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"MLFLOW_ENABLED\") == \"true\":\n",
    "    print(\"Starting run\")\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "    mlflow.set_experiment(\"such-toxic\")\n",
    "    mlflow.pytorch.autolog()\n",
    "    mlflow.start_run()\n",
    "\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"learning_rate\", lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embedded_dataset_path) as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "if os.getenv(\"MLFLOW_ENABLED\") == \"true\":\n",
    "    mlflow.log_artifact(embedded_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPK5CKUXBrsq",
    "outputId": "564d1dd9-98b0-4ab9-eaf4-e2127e14c4f1"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "class SuchToxicDataset(Dataset):\n",
    "    def __init__(self, rows):\n",
    "        self.rows = rows\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.rows[idx]\n",
    "        encoded_input = tokenizer(\n",
    "            row[\"comment_text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        return (\n",
    "            encoded_input[\"input_ids\"],\n",
    "            encoded_input[\"attention_mask\"],\n",
    "            torch.tensor(\n",
    "                [\n",
    "                    row[\"toxic\"],\n",
    "                    row[\"severe_toxic\"],\n",
    "                    row[\"obscene\"],\n",
    "                    row[\"threat\"],\n",
    "                    row[\"insult\"],\n",
    "                    row[\"identity_hate\"],\n",
    "                ],\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "train, test = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "train_dataset = SuchToxicDataset(list(train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(\"input_ids: \", batch[0].shape)\n",
    "    print(\"attention_mask: \", batch[1].shape)\n",
    "    print(\"labels: \", batch[2].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "model = TextClassifier(num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "ARgqk2bIIrMV",
    "outputId": "ea2ea464-11f0-4f63-9ff3-e3969874ec27"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "pbar = tqdm(range(epochs), desc=\"Epoch\")\n",
    "pbar_trainloader = tqdm(\n",
    "    train_loader,\n",
    "    desc=\"Train Loader\",\n",
    "    leave=False,\n",
    "    total=len(train_loader),\n",
    ")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for input_ids, attn_mask, labels in pbar_trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = input_ids.squeeze(1).to(device)\n",
    "        attn_mask = attn_mask.squeeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        prediction = model(input_ids, attn_mask)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    pbar.set_postfix(loss=avg_loss)\n",
    "\n",
    "    if os.getenv(\"MLFLOW_ENABLED\") == \"true\":\n",
    "        mlflow.log_metric(\"loss\", avg_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.savefig(\"../target/training_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": epochs,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    f\"../checkpoints/{model_name}.pth\",\n",
    ")\n",
    "\n",
    "if os.getenv(\"MLFLOW_ENABLED\") == \"true\":\n",
    "    mlflow.pytorch.log_model(model, \"such-toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred, threshold=0.8):\n",
    "    labels = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        pred = 1 if pred >= threshold else 0\n",
    "        if true == pred:\n",
    "            labels += 1\n",
    "    return labels / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "total_accuracy = 0\n",
    "test_dataset = SuchToxicDataset(list(test)[:10])\n",
    "\n",
    "for input_ids, attn_mask, label in tqdm(test_dataset, desc=\"Test Dataset\"):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    prediction = model(input_ids, attn_mask)\n",
    "    output = prediction.cpu().detach().numpy().tolist()[0]\n",
    "    total_accuracy += accuracy(label, output)\n",
    "\n",
    "print(total_accuracy / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"What a bunch of fucking nerds...\"\n",
    "\n",
    "\n",
    "tokens = tokenizer(\n",
    "    test_str,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "input_ids = tokens[\"input_ids\"].squeeze(1).to(device)\n",
    "attn_mask = tokens[\"attention_mask\"].squeeze(1).to(device)\n",
    "\n",
    "output = model(input_ids, attn_mask)\n",
    "output = output.cpu().detach().numpy().tolist()[0]\n",
    "\n",
    "print(\"Toxic: \", output[0])\n",
    "print(\"Severe Toxic: \", output[1])\n",
    "print(\"Obscene: \", output[2])\n",
    "print(\"Threat: \", output[3])\n",
    "print(\"Insult: \", output[4])\n",
    "print(\"Identity Hate: \", output[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"MLFLOW_ENABLED\") == \"true\":\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
